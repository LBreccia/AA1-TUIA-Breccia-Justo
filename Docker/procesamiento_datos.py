# -*- coding: utf-8 -*-
"""procesamiento_datos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JEEipqahbrS6Xxs6ANCn6a1u0dn2FHDV
"""

import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
import joblib
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.metrics import Recall

def imputacion_knn(df):
  """" Esta función hace una imputación knn para las columnas con valores
  numéricos del dataframe que recibe. Devuelve el dataframe imputado."""
  # Filtramos solo columnas numéricas
  df_numerico = df.select_dtypes(include=[np.number])

  # Aplicamos KNNImputer solo a las columnas numéricas
  knn_imputer = KNNImputer()
  df_numerico_imputado = pd.DataFrame(knn_imputer.fit_transform(df_numerico), columns=df_numerico.columns)

  # Se reinicia el índice de ambos DataFrames antes de concatenar
  df_numerico_imputado.reset_index(drop=True, inplace=True)
  df_no_numerico = df.select_dtypes(exclude=[np.number]).reset_index(drop=True)

  # Unimos nuevamente con las columnas no numéricas
  df_clima = pd.concat([df_no_numerico, df_numerico_imputado], axis=1)
  return df_clima


def seleccionar_codificar_ciudad_date(df):
  """ Esta función recibe un dataframe con ciertas columnas conocidas:
      - De la columna Location se queda con un subconjunto de ciudades.
      - Realiza OneHotEncoder a dicha variable
      - De la columna Date, separa el Mes como una nueva variable.
      Devuelve el dataframe codificado.
  """
  ciudades = ['Williamtown', 'AliceSprings', 'Katherine', 'Launceston',
       'MountGinini', 'Dartmoor', 'Watsonia', 'Portland', 'Townsville',
       'Bendigo']
  df_clima = df[df['Location'].isin(ciudades)]
  encoder = OneHotEncoder(sparse_output=False)
  ciudades_one_hot = encoder.fit_transform(df_clima[['Location']])

  # Creamos un nuevo dataframe con la codificación One-Hot
  ciudades_df = pd.DataFrame(ciudades_one_hot, columns=encoder.get_feature_names_out(['Location']))

  # Combinamos el dataframe original con el nuevo de ciudades codificadas
  df_clima = pd.concat([df_clima, ciudades_df], axis=1)

  #Separamos de la variable fecha el mes y lo añadimos en una columna aparte
  df_clima['Date'] = pd.to_datetime(df_clima['Date'])
  df_clima['Mes'] = df_clima['Date'].dt.month

  return df_clima


def correcciones_dir_rain(df):
  """ Esta función recibe un dataframe con ciertas columnas conocidas y realiza lo siguiente:
      - Corrige "errores" en columnas WindGustDir, WindDir9am, WindDir3pm
      - Reemplaza "yes"/"no" por 1/0 en RainToday
      - Aplica imputación por moda por mes a las variables anteriores.
      - Codifica las variables anteriores.
      Devuelve el dataframe con las correcciones.
  """
  df['WindGustDir'] = df['WindGustDir'].replace({'ENE': 'NE', 'SSW': 'SW', 'ESE': 'SE', 'SSE': 'SE', 'WNW': 'NW', 'WSW': 'SW', 'NNW': 'NW', 'NNE': 'NE'})
  df['WindDir9am'] = df['WindGustDir'].replace({'ENE': 'NE', 'SSW': 'SW', 'ESE': 'SE', 'SSE': 'SE', 'WNW': 'NW', 'WSW': 'SW', 'NNW': 'NW', 'NNE': 'NE'})
  df['WindDir3pm'] = df['WindGustDir'].replace({'ENE': 'NE', 'SSW': 'SW', 'ESE': 'SE', 'SSE': 'SE', 'WNW': 'NW', 'WSW': 'SW', 'NNW': 'NW', 'NNE': 'NE'})
  df['RainToday'] = np.where(df['RainToday'] == 'Yes', 1, 0)
  moda_por_mes_windgustdir = joblib.load('moda_por_mes_windgustdir.pkl')
  moda_por_mes_winddir9a= joblib.load('moda_por_mes_winddir9am.pkl.pkl')
  moda_por_mes_winddir3pm = joblib.load('moda_por_mes_winddir3pm.pkl')
  moda_por_mes_raintoday = joblib.load('moda_por_mes_raintoday.pkl')

  for i in range(1,13):
    imputer1 = SimpleImputer(strategy='constant', fill_value = moda_por_mes_windgustdir[i])
    imputer2 = SimpleImputer(strategy='constant', fill_value = moda_por_mes_winddir9am[i])
    imputer3 = SimpleImputer(strategy='constant', fill_value = moda_por_mes_winddir3pm[i])
    imputer4 = SimpleImputer(strategy='constant', fill_value = moda_por_mes_raintoday[i])
    # Imputar solo las filas correspondientes al mes actual para WindGustDir
    df.loc[df['Mes'] == i, 'WindGustDir'] = imputer1.fit_transform(
          df.loc[df['Mes'] == i, 'WindGustDir'].values.reshape(-1, 1))
    # Imputar solo las filas correspondientes al mes actual para WindDir9am
    df.loc[df['Mes'] == i, 'WindDir9am'] = imputer2.fit_transform(
          df.loc[df['Mes'] == i, 'WindDir9am'].values.reshape(-1, 1))
    # Imputar solo las filas correspondientes al mes actual para WindDir3pm
    df.loc[df['Mes'] == i, 'WindDir3pm'] = imputer3.fit_transform(
          df.loc[df['Mes'] == i, 'WindDir3pm'].values.reshape(-1, 1))
    # Imputar solo las filas correspondientes al mes actual para RainToday
    df.loc[df['Mes'] == i, 'RainToday'] = imputer4.fit_transform(
          df.loc[df['Mes'] == i, 'RainToday'].values.reshape(-1, 1))

  direcciones = {
      'E': 0,
      'NE': math.pi / 4,
      'N': math.pi/2,
      'NW': 3*math.pi / 4,
      'W': math.pi ,
      'SW': 5*math.pi / 4,
      'S': 3*math.pi /2 ,
      'SE': 7*math.pi / 4}

  asignar_coordenadas = joblib.load('asignar_coordenadas.pkl')
  asignar_coordenadas_gustdir = joblib.load('asignar_coordenadas_gustdir.pkl')
  asignar_coordenadas_dir9am = joblib.load('asignar_coordenadas_dir9am.pkl')
  asignar_coordenadas_dir3pm = joblib.load('asignar_coordenadas_dir3pm.pkl')

  # Aplicamos la función a la columna Windgustdir
  df[['x_gust', 'y_gust']] = df['WindGustDir'].apply(asignar_coordenadas_gustdir)
  # Aplicar la función a la columna WindDir9am
  df[['x_dir9am', 'y_dir9am']] = df['WindDir9am'].apply(asignar_coordenadas_dir9am)
  # Aplicar la función a la columna WindDir3pm:
  df[['x_dir3pm', 'y_dir3pm']] = df['WindDir3pm'].apply(asignar_coordenadas_dir3pm)
  # Aplicar la función a la columna Mes
  df[['x_mes', 'y_mes']] = df['Mes'].apply(asignar_coordenadas)

  return df

def procesar_data(df):
  """ Esta función recibe un DataFrame y aplica varias funciones para
  procesar la información. Devuelve el DataFrame procesado."""
  df_imputacion_num = imputacion_knn(df)
  df_clima = seleccionar_codificar_ciudad_date(df_imputacion_num)
  df_clima2 = correcciones_dir_rain(df_clima)
  return df_clima2

class NeuralNetworkTensorFlow:
    """
        Este es un modelo con TensorFlow.
        En esta clase, se construye el modelo,
        se define como se fitea el modelo,
        y como se hacen las predicciones.
    """
    def __init__(self, learning_rate=0.01, epochs=500, hidden_units=2, hidden_layers=1):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.hidden_units = hidden_units  # Número de neuronas en la capa oculta
        self.hidden_layers = hidden_layers # Número de capas ocultas
        self.model = None

    def build_model(self):
        """
            Para construir el modelo es necesario una arquitectura, un optimizador y una función de pérdida.
            La arquitectura se construye con el método Sequential, que coloca
            secuencialmente las capas que uno desea.
            Las capas "Dense" son las fully connected.
            Se agregan capas ocultas,
            y una capa de salida de regresión (una única neurona).

            El optimizador y la función de pérdida se especifican dentro de un compilador.

            Con este método, lo que se devuelve es el modelo sin entrenar, sería equivalente a escribir LinearRegression()
            en el caso de la regresión lineal.
        """
        model = Sequential()

        # Agregar la primera capa oculta (necesita especificar input_shape)
        model.add(Dense(self.hidden_units, activation='relu', input_shape=(X_train_scaled.shape[1],)))

        # Agregar capas ocultas adicionales (sin input_shape, ya se ajusta automáticamente)
        for _ in range(self.hidden_layers - 1):  # self.hidden_layers indica el número total de capas ocultas
            model.add(Dense(self.hidden_units, activation='relu'))

        # Agregar la capa de salida
        model.add(Dense(1))  # Una neurona para regresión

        optimizer = Adam(learning_rate=self.learning_rate)

        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'Recall'])

        self.model = model

        # imprimir la cantidad de parámetros a modo de ejemplo
        print("n° de parámetros:", model.count_params())
        return model

    def fit(self, X, y):
      """ Esta es la función donde se entrena el modelo, hay un learning rate e iteraciones,
      la función que fitea devuelve una historia de pérdida, que vamos a guardar para graficar la evolución. """
      X = np.array(X)
      y = np.array(y)

      if self.model is None:
        self.build_model()

      early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)

      history = self.model.fit(X, y, epochs=self.epochs, batch_size=32, verbose=0, class_weight=class_weights, callbacks=[early_stopping])

      return history.history

    def predict(self, X):
        X = np.array(X)
        predictions = self.model.predict(X)
        return predictions
